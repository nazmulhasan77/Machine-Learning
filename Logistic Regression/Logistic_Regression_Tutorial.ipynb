{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcac3d27",
   "metadata": {},
   "source": [
    "\n",
    "# ü§ñ Logistic Regression in Machine Learning\n",
    "\n",
    "## üîç Overview\n",
    "\n",
    "**Logistic Regression** is a **supervised learning algorithm** used for **binary classification** tasks.\n",
    "\n",
    "It models the probability that a given input belongs to **class 1** (vs. class 0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeae406",
   "metadata": {},
   "source": [
    "\n",
    "## üìê Key Concepts\n",
    "\n",
    "- **Purpose**: Predict whether an input belongs to class 1 or class 0.\n",
    "- **Output**: A probability value between **0 and 1**.\n",
    "- **Threshold**: Usually 0.5 ‚Äì if the output ‚â• 0.5 ‚Üí class 1, else class 0.\n",
    "\n",
    "### ‚úÖ Logistic Regression Equation\n",
    "\n",
    "\\[\n",
    "P(Y=1|X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_nX_n)}}\n",
    "\\]\n",
    "\n",
    "This is the **sigmoid function** applied to a **linear combination** of input features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9564abc7",
   "metadata": {},
   "source": [
    "\n",
    "## üîÑ Machine Learning Pipeline with Logistic Regression\n",
    "\n",
    "### 1. Collect Data\n",
    "- Example: Dataset with features like age, income, and purchase (0 = no, 1 = yes)\n",
    "\n",
    "### 2. Preprocess the Data\n",
    "- Handle missing values\n",
    "- Normalize or scale features\n",
    "- Encode categorical variables\n",
    "\n",
    "### 3. Split the Dataset\n",
    "- **Training set** (e.g., 80%)\n",
    "- **Test set** (e.g., 20%)\n",
    "\n",
    "### 4. Train the Model\n",
    "- Learn weights using **gradient descent**\n",
    "- Minimize the **log loss function**\n",
    "\n",
    "### 5. Make Predictions\n",
    "- Output probabilities ‚Üí classify based on threshold\n",
    "\n",
    "### 6. Evaluate Performance\n",
    "Metrics:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score\n",
    "- ROC-AUC Score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0ab261",
   "metadata": {},
   "source": [
    "\n",
    "## üìà Decision Boundary\n",
    "\n",
    "Logistic Regression finds a **linear decision boundary** in feature space:\n",
    "- For 2 features ‚Üí straight line\n",
    "- For more ‚Üí hyperplane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac30eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9736842105263158\n",
      "Precision: 0.9722222222222222\n",
      "Recall: 0.9859154929577465\n",
      "F1 Score: 0.9790209790209791\n",
      "ROC-AUC Score: 0.99737962659679\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Step 1: Load dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Step 6: Evaluate performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca53dc",
   "metadata": {},
   "source": [
    "\n",
    "## üìå Use Cases\n",
    "\n",
    "- **Email spam detection**  \n",
    "  Classify emails as spam or not spam.\n",
    "\n",
    "- **Credit risk modeling**  \n",
    "  Predict whether a person is likely to default on a loan.\n",
    "\n",
    "- **Disease diagnosis**  \n",
    "  Example: Classify tumors as malignant or benign.\n",
    "\n",
    "- **Customer churn prediction**  \n",
    "  Predict if a customer is likely to leave a service.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e00d158",
   "metadata": {},
   "source": [
    "\n",
    "## ‚ö†Ô∏è Limitations\n",
    "\n",
    "- Assumes a **linear relationship** between input features and the **log-odds** of the output.\n",
    "- Not suitable for **non-linear** or **complex data** like images or speech.\n",
    "- **Sensitive to outliers** and **multicollinearity** among features.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
